{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/minyou73/study/blob/main/Youtube_Video_Summarization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YGBuFsNCjiQh"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GAWSnx7sjtyh"
      },
      "source": [
        "Youtube Video Summarization\n",
        "\n",
        "1. 유튜브 영상 다운로드(음성만)\n",
        "2. speech to text(transcribe)-openAI Whisper (말을 텍스트로 변환)\n",
        "3. Map-reduce summarization - Lanchain, openAI(방대한 분량을 조그만 단위로 나눠서 합치기)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LbMxYa-mtnBF"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4UetFkVXjkjo",
        "outputId": "0cf279b7-8d6c-414b-d0f4-b28aff243243"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[33m\r0% [Working]\u001b[0m\r            \rGet:1 http://security.ubuntu.com/ubuntu jammy-security InRelease [110 kB]\n",
            "\u001b[33m\r0% [Connecting to archive.ubuntu.com (185.125.190.39)] [1 InRelease 2,588 B/110\u001b[0m\r                                                                               \rGet:2 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,626 B]\n",
            "Get:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [119 kB]\n",
            "Get:6 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [810 kB]\n",
            "Hit:7 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy InRelease\n",
            "Get:8 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,082 kB]\n",
            "Hit:9 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:11 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Get:12 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [1,695 kB]\n",
            "Hit:13 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:14 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [1,975 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,375 kB]\n",
            "Fetched 7,172 kB in 3s (2,533 kB/s)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "45 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 45 not upgraded.\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m798.6/798.6 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!sudo apt update && sudo apt install ffmpeg\n",
        "!pip install -q openai-whisper pytube\n",
        "!pip install -q openai tiktoken langchain\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ShLK1Q2akaAT"
      },
      "source": [
        "\n",
        "\n",
        "```\n",
        "# 코드로 형식 지정됨\n",
        "```\n",
        "\n",
        "Download YouTube video"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "W1vAKiKWkEyk",
        "outputId": "54348b60-a590-42de-a461-0a9126660a41"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/./input.mp3'"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from pytube import YouTube\n",
        "\n",
        "yt = YouTube('https://www.youtube.com/watch?v=GkhIVshS7jM')\n",
        "\n",
        "yt.streams.filter(only_audio=True).first().download(\n",
        "    output_path='.', filename='input.mp3')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "My0dQUjxk_L9"
      },
      "source": [
        "Transcribe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gmcb25Zpk1Xu",
        "outputId": "a257f9ea-35f1-4731-c633-9da0249a788d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|████████████████████████████████████████| 139M/139M [00:00<00:00, 170MiB/s]\n"
          ]
        }
      ],
      "source": [
        "import whisper\n",
        "\n",
        "model = whisper.load_model(\"base\")\n",
        "# 음성에서 텍스트로 전환"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iwe-8iKUlTVU"
      },
      "source": [
        "30초 이상 오디오 데이터 처리 방법"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        },
        "id": "2BWHKUdplXMt",
        "outputId": "19b97648-6371-41a7-c339-e7b7fbc90857"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:115: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "' 안녕하세요. 최근에 어떤 스타트업 대표님을 만나서 이야기할 기회가 있었는데요. 그 대표님이 그런 말씀을 하시더라고요. 요즘에 옛날 친구들, 학창시절 때 친구들을 만나도 좀 옛날 만큼 재밌지 않다는 느낌을 많이 받는다. 맨날 만나도 옛날에 했던 똑같은 얘기들을 반복하고 지금 그 친구들이 무슨 생각을 갖고 있는지 자신의 삶에 대해서 무슨 생각을 갖고 있는지 그런 것들을 서로 깊이 대화를 나누고 진짜로 통한다는 느낌을 바퀴가 쉽지 않은 것 같더라. 이렇게 말씀을 하셨고 그리고 그 분이 하셨던 표현 중에 제 마음에 되게 와다았던 게 친구'"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "result = model.transcribe(\"input.mp3\")\n",
        "result[\"text\"][:300]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z88S_TGnlFOV",
        "outputId": "ba41d7d6-1d5b-4d7c-ae51-1f19a039158f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'id': 0,\n",
              "  'seek': 0,\n",
              "  'start': 0.0,\n",
              "  'end': 1.22,\n",
              "  'text': ' 안녕하세요.',\n",
              "  'tokens': [50364, 19289, 13, 50425],\n",
              "  'temperature': 0.0,\n",
              "  'avg_logprob': -0.21012464183971194,\n",
              "  'compression_ratio': 1.736413043478261,\n",
              "  'no_speech_prob': 0.016844864934682846},\n",
              " {'id': 1,\n",
              "  'seek': 0,\n",
              "  'start': 1.22,\n",
              "  'end': 3.96,\n",
              "  'text': ' 최근에 어떤 스타트업 대표님을 만나서',\n",
              "  'tokens': [50425,\n",
              "   37349,\n",
              "   1517,\n",
              "   15620,\n",
              "   30675,\n",
              "   8857,\n",
              "   11534,\n",
              "   37970,\n",
              "   9466,\n",
              "   1638,\n",
              "   38841,\n",
              "   2393,\n",
              "   50562],\n",
              "  'temperature': 0.0,\n",
              "  'avg_logprob': -0.21012464183971194,\n",
              "  'compression_ratio': 1.736413043478261,\n",
              "  'no_speech_prob': 0.016844864934682846},\n",
              " {'id': 2,\n",
              "  'seek': 0,\n",
              "  'start': 3.96,\n",
              "  'end': 5.36,\n",
              "  'text': ' 이야기할 기회가 있었는데요.',\n",
              "  'tokens': [50562, 37576, 7999, 7047, 15048, 1453, 15972, 14586, 13, 50632],\n",
              "  'temperature': 0.0,\n",
              "  'avg_logprob': -0.21012464183971194,\n",
              "  'compression_ratio': 1.736413043478261,\n",
              "  'no_speech_prob': 0.016844864934682846}]"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "result[\"segments\"][:3]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L2R-DWgOlyo-",
        "outputId": "b6892249-7ab9-4211-9c4e-1ec3057a7ac5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "5194"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(result[\"text\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_up7egCfmjI_"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7nU-EgPtmmqL"
      },
      "source": [
        "Map-reduce summarization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IBYXhnrXmpK1"
      },
      "source": [
        "Text splitter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ugMDx7P1mob0",
        "outputId": "9dbbd6e6-4c3b-4e7c-b051-dfe2cea43383"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "6"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "!pip install -q openai tiktoken langchain\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.schema.document import Document\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=1000,\n",
        "    chunk_overlap=50, #겹쳐서 자름\n",
        "    length_function=len,  #글자수 세는 방법\n",
        ")\n",
        "\n",
        "docs = [Document(page_content=x) for x in text_splitter.split_text(result[\"text\"])]\n",
        "\n",
        "split_docs = text_splitter.split_documents(docs)\n",
        "\n",
        "len(split_docs)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "701vxhBhniuH",
        "outputId": "671ac111-2190-449a-f5ef-08ba475568e7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Document(page_content='안녕하세요. 최근에 어떤 스타트업 대표님을 만나서 이야기할 기회가 있었는데요. 그 대표님이 그런 말씀을 하시더라고요. 요즘에 옛날 친구들, 학창시절 때 친구들을 만나도 좀 옛날 만큼 재밌지 않다는 느낌을 많이 받는다. 맨날 만나도 옛날에 했던 똑같은 얘기들을 반복하고 지금 그 친구들이 무슨 생각을 갖고 있는지 자신의 삶에 대해서 무슨 생각을 갖고 있는지 그런 것들을 서로 깊이 대화를 나누고 진짜로 통한다는 느낌을 바퀴가 쉽지 않은 것 같더라. 이렇게 말씀을 하셨고 그리고 그 분이 하셨던 표현 중에 제 마음에 되게 와다았던 게 친구들이 보니까 자신의 인생을 점을 찍어서 살아가는 것 같다 라는 느낌을 들지가 않더라. 라고 말씀을 하셨습니다. 그만큼 자신의 인생의 지점 지점들을 잘 기억하고 그것들이 무슨 의미를 갖는지에 대해서 성찰하고 그것을 다른 사람들한테 이야기하고 그럴 려는 자세가 좀 잘 없는 것 같더라. 그래서 요즘에 만나도 잘 재미가 없다. 그런 이야기를 하셨습니다. 아마 얘 친구를 만났는데 생각보다 옛날보다 재밌지가 않네. 그렇게 느끼시는 경우가 성인인 대신 분들 중에는 정말 많을 겁니다. 아직 학창시절을 보내고 계신 분들은 잘 모를 수도 있는데 지금 고등학생 때 엄청나게 친했다고 해도 나중에 한 5년 10년 정도 지나서 다시 만났을 때 옛날 같지 않다라는 느낌을 받는 경우가 굉장히 흔합니다. 그러면서 우리의 인간 관계가 조금씩 조금씩 좁아지게 되죠. 나이가 들면서 계속 새로운 사람들을 더 많이 만나고 옛날 친구들이랑 사이가 소먹해지는 것만 상관없을 텐데 얘 친구들이랑의 사이는 일반적으로 계속해서 좀 멀어지는 경우가 많은 반면에 새로 사람을 또 에너지를 들여서 사기게 되는 경우는 되게 적거든요. 그래서 나이가 들면서 우리의 인간 관계는 점차 좁아지게 되는 게 일반적인 것 같습니다. 이러한 우리 삶의 괴적은 제가 최근에 읽을 소설 중에 하나인 미셀 우열백의 세로톤이네 아주 잘 묘사가 돼 있습니다. 그 소설에서 주인공은 도는 그냥 인양전양 잘 벌어요.'),\n",
              " Document(page_content='아주 잘 묘사가 돼 있습니다. 그 소설에서 주인공은 도는 그냥 인양전양 잘 벌어요. 공무원인데 좀 특수직 공무원이라서 일반 공무원에 비해서 급여를 상당히 많이 봤습니다. 그런데 연인과의 사이도 좀 애매하고 그리고 이렇탈 가깝게 지는 친구도 적고 그래서 삶의 원한 무려함을 느껴서 아 나 이제 어떡하지? 그렇게 생각을 하다가 얘 친구들을 좀 만나봐야겠다. 옛날에 내가 만났던 연인들 그걸 가서 그냥 다시 한번 만나보고 아니면 내가 대학교 때 가깝게 지는 또 친구들을 다시 찾아가서 이야기를 나눠봐야겠다. 그러면 뭐가 좀 달라지지 않을까? 이런 생각을 하고 길을 떠나게 되는데요. 그런데 한결같이 다 옛날에 만났었던 사람들을 만나도 예정같이 느껴지지가 않는 겁니다. 특히 한 대학교 때 친구를 만내러 갔는데 이 사람은 농대를 나왔어요. 그래서 그 친구도 농대의 친구인데 그 농대를 나온 대부분의 학생들은 농업관련된 다른 일을 하는 반면에 이 친구 같은 경우는 실제로 농부가 된 케이스였습니다. 그 집안에서 물려받은 땅이 되게 넓어서 거기에 가서 농사를 하는데 근데 농사일이 그렇게까지 적성에 맞지가 않는 거예요. 그 큰 부지를 운영하는 게 되게 힘들고 그런데 이 소설이 프랑스 소설인데요. 프랑스의 농업 환경은 점점 더 안 좋아져서 해외에서 값산 수임무들이 들어오다 보니까 자신의 농지의 경쟁력은 계속 낮아져 가고 그래서 먹고 살기도 넉넉시가 않고 그래서 오랜만에 만나러 갔더니 친구가 맞냐 하고 반겨주긴 하는데 계속 술을 조금씩 들이키고 있는 것 같고 아내랑은 이혼에서 딸들이 있는데 딸들도 아내가 데려가서 키우고 그래서 참 외롭게 그 시골에서 늘고 가는구나 라는 느낌을 받으면서 그 주인공도 덩달아 씁쓸해지는 그런 케이스가 있었는데요. 정확하게 이런 케이스랑 똑같은 건 아니더라도 삶을 살다 보면 얘 친구들 중에 이렇게 좀 빛이 바래가는 그런 경우가 참 많은 것 같습니다. 그래서 나이가 들면서도 인간간계가 점차 줄어들지 않을려면 지속적으로 계속 만나도 계속 새로운 종류의 즐거움과'),\n",
              " Document(page_content='인간간계가 점차 줄어들지 않을려면 지속적으로 계속 만나도 계속 새로운 종류의 즐거움과 가르침을 뿜어내는 그런 종류의 사람들을 많이 만나고 나 또한 그런 사람이 되어야 할 텐데요. 근데 많은 사람들이 사실 그런 삶을 살지 못하는 거죠. 왜 그럴까? 애 대해서 제가 한번 생각해봤는데 아까 그 스타트업 대표님이 말씀하신 대로 사람들이 자신의 삶의 점을 찍어서 각각의 사건들의 의미를 부여하고 그것을 엮어서 자신의 이야기를 만들어 내지 못한다 라는 느낌을 받았어요. 그래서 오랜만에 친구를 만나도 들려줄 이야기가 없는 거죠. 오랜만에 만났는데 막상 별로 새롭게 할 얘기가 없는 거죠. 그래서 계속 옛날에 했던 얘기들만 대풀이 하고 옛날에 같이 공유하는 추억들만 대풀이 하고 결국에 내가 왕년의 말이야. 라는 그런 식의 확법도 저는 그렇게 자신의 현재적인 삶 속에서 새로운 의미를 만들어내지 못하기 때문에 과거에 집착해서 생겨나는 확법이라고 생각하거든요. 그리고 가끔은 만나면 자기 얘기만 지나치게 주구장참 많이 하려고 하는 친구가 있습니다. 그런 친구를 봐도 참 재미가 없다고 느끼죠. 그런데 사실 자기 얘기를 많이 한다고 해서 그것 자체로 재미가 없어지는 건 아니거든요. 자기 얘기를 많이 하는데 재미가 없는 이유는 그 자기 얘기가 진정한 힘에서 자기 얘기 아니기 때문입니다. 자신에 대해서 이야기하고는 있지만 사실은 남들이 하는 이야기를 반복할 뿐이고 남들이 평균적으로 갖는 시선 남들이 평균적으로 갖는 삶의 자세 그런 것들을 그냥 무기판적으로 받아들이면서 그걸 앵무새처럼 반복하는 사람을 볼 때 우리는 좀 재미가 없다고 느끼죠. 대표적으로 부동산 얘기 같은 거로 막 한다던가 연봉 얘기, 자동차 얘기 이렇게 그냥 남들이 많이 관심을 갖는 주제에서 자신의 입으로 이야기할 뿐이지 그게 진정으로 자기 얘기는 아닐 때 자신의 삶에 대한 유임의 이야기가 아닐 때 우리는 그 사람과 굳이 더 길게 대화하고 싶지 않다 라는 느낌을 봤습니다. 저는 이 문제에 대해 생각하면서 제가 예전에 영상으로도'),\n",
              " Document(page_content='싶지 않다 라는 느낌을 봤습니다. 저는 이 문제에 대해 생각하면서 제가 예전에 영상으로도 한번 소개해드렸던 Cherecagore의 회상 이라는 개념이 떠올랐습니다. Cherecagore라는 철학제가 말하는 회상은 과거를 먼 발치해서 바라보면서 그 의미를 곱시구면서 그 안에 담겨진 현재적인 이야기들을 통합적으로 써내려가는 그런 능력을 뜻합니다. Cherecagore는 성숙한 어른이 되려면 반드시 회상의 능력을 갖춰야 된다고 생각했어요. Cherecagore가 생각하기에 어린 아이들은 기억에 능력은 있지만 회상의 능력은 없습니다. 단편 단편 한 가지 일들을 아이들은 아주 좋은 기억력으로 잘 기억하지만 그것들이 먼 긴 시간 좀 맥락에서 어떤 의미를 갖는지 통합적으로 파악해내지는 못한다는 거죠. 다른 사람들을 만났을 때 자신의 이야기를 흥미롭게 잘 풀어낼 수 없는 사람은 보통 이런 회상의 능력이 잘 발달하지 않은 케이스라고 봅니다. 과거의 사건을 기억을 하고는 있기 때문에 그 사건에 대해서 계속해서 대풀이 해서 이야기는 하지만 그 사건이 그래서 지금 현재 지금 2023년, 2024년에 어떤 의미를 갖는지 통합적으로 이야기를 써내려가면서 파악하지는 못하는 거죠. 그런 사람의 이야기를 계속 듣고 있으면 질린다라는 느낌을 받을 수밖에 없습니다. 그리고 또 저는 이 Cherecagore의 회상 개념과 비슷하게 최근에 제가 영상으로 올렸던 Seneca의 시간 개념도 떠올랐습니다. Seneca 같은 경우는 우리가 시간을 진정으로 풍부하게 잘 살아가고 죽기 전에 후회하지 않는 아 내가 시간을 잘 보냈구나 라는 삶을 살려면 과거부터 미래까지 이어지는 시간을 통합적으로 이해할 수 있는 능력이 필요하다고 생각했습니다. 요즘에 사람들은 현재를 살아라 너의 현재의 집중에 진짜 시간을 잘 살 수 있다 라고 이야기를 하지만 사실 제가 생각하게 현재를 진정으로 잘 산다는 건 현재를 그 흘러가는 찰라의 순간으로 수만 보는 게 아니라 이 현재가 과거와 연관돼서 또 앞으로 다가올 미래와 관련해서'),\n",
              " Document(page_content='수만 보는 게 아니라 이 현재가 과거와 연관돼서 또 앞으로 다가올 미래와 관련해서 어떤 의미를 갖는지 잘 파악하는 사람들이라고 생각합니다. 그런데 이런 넓은 시간관형을 갖지 않은 사람들은 한 가지 시간에만 매물되어서 살아갑니다. 과거에만 매물돼 있다든지 아니면 현재만 매물되어서 지금 눈앞에 당장 주어진 이래만 관심을 갖는다든지 아니면 미래에 다가올 이래만 진화식에 관심을 갖는다는지 예를 들면 아 5년 후에 집값이 어떻게 될까 이 문제에만 계속 관심을 갖으면서 그래서 현재 그게 무슨 의미를 갖는데 현재 그게 너의 삶에서 어떤 재밌는 이야기로 들려줄 수 있을 만한 요소로 갔냐 이런 거에 대해서는 잘 이야기를 전혀 하려고 하지 않는 거죠. 이런 경우에 우리는 아 이 사람과의 대화가 재미없구나 라는 느낌을 받게 됩니다. 한 가지의 철학적 관영만 더 소개를 드리자면 철학적 시문드 보부하르는 내재와 초월을 구결하고요. 인간은 항상 초월을 향해서 나가야 된다고 생각을 합니다. 내재는 어떤 상태 안에 그대로 몸을 넣는 걸 뜻하고요. 초월은 그거 바깥으로 나가는 걸 뜻하는데요. 간단하게 말하자면 시문드 보부하라는 대표적으로 패미니스트 철학적으로 알려져 있죠. 여성성이라는 거는 내재적이지 않고 사실 초월적이다. 무엇이 여성성이 될지는 이미 규정되어 있고 그 안에서만 돌아다녀야 되는 게 아니라 그 바깥으로 나갈 수 있다. 충분히 변화를 도망할 수 있다. 이런 의식을 항상 갖고 사는 게 중요하다고 생각했던 사람인데 우리가 꼭 이런 패미니스트적인 관점에서 이 사람의 생각을 받아들이지 않더라도 각한 사람한 사람의 인생과 어떤 하나의 시점들이 다 저는 초월적이라고 생각하거든요. 인생의 하나하나의 포인트들은 다 그 포인트 안에 매물되어서 내재적인 상태만 빠져 있는 게 아니라 충분히 그것을 빠져나워서 다른 포인트들과 사무적용하면서 새로운 의미로 나아갈 수 있다고 생각합니다. 그래서 우리는 항상 초월적인 의식을 가시려고 노력할 때만 나 스스로도 흥미로운 나의 이야기를 들려줄 수 있는 사람이'),\n",
              " Document(page_content='의식을 가시려고 노력할 때만 나 스스로도 흥미로운 나의 이야기를 들려줄 수 있는 사람이 되고 다른 사람의 이야기 속에서도 흥미로운 지점들을 잘 파악할 수 있는 그런 사람이 되지 않을까 싶습니다. 이렇게 되야만 우리가 나이가 들면서 점점 인간관계가 쫓아진다 나는 만날 사람이 없다. 요즘에 다 그 사람이 그 사람인 것 같다. 이런 느낌을 받는 게 아니라 좋은 사람들과 잘 어울리면서 외롭지 않다는 느낌을 받을 수 있지 않을까 그렇게 생각을 해봅니다. 여러분은 요즘에 인간관계에 대해서 어떤 생각을 갖고 계신가요? 충분히 사람들이 잘 만나면서 살아가고 있다고 생각하시나요? 아니면 좀 사람 만나는 게 재미없다고 느끼시나요? 이런 주제에 대해서 많은 생각을 댓글로 남겨주시면 참 감사드리겠습니다. 제가 오늘 준비한 내용은 여기까지고요. 다음에 또 재밌는 영상으로 돌아오겠습니다. 감사합니다.')]"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "split_docs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wWSTcmBsoHc5"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-hU2vW_ooeGi"
      },
      "source": [
        "Prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DWO3Q7tzphPt"
      },
      "outputs": [],
      "source": [
        "!pip install -q openai tiktoken langchain\n",
        "\n",
        "from langchain.chains.mapreduce import MapReduceChain\n",
        "from langchain.chains import ReduceDocumentsChain, MapReduceDocumentsChain\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.chains.llm import LLMChain\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.chains.combine_documents.stuff import StuffDocumentsChain\n",
        "\n",
        "openai_api_key = \"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\"\n",
        "\n",
        "llm = ChatOpenAI(temperature=0, openai_api_key=openai_api_key)\n",
        "\n",
        "# Map prompt\n",
        "map_template = \"\"\"The following is a set of documents\n",
        "{docs}\n",
        "Based on this list of docs, please identify the main themes\n",
        "Helpful Answer:\"\"\"\n",
        "#여러개의 set으로 된 document가 있는데 list of docs를 기반으로해서 메인 주제들을 찾아달라\n",
        "\n",
        "map_prompt = PromptTemplate.from_template(map_template)\n",
        "\n",
        "\n",
        "\n",
        "# Reduce prompt\n",
        "reduce_template = \"\"\"The following is set of summaries:\n",
        "{doc_summaries}\n",
        "Take these and distill it into a final, consolidated summary of the main themes.\n",
        "The final answer is a single paragraph of about 100 words and must be in Korean.\n",
        "Helpful Answer:\"\"\"\n",
        "\n",
        "reduce_prompt = PromptTemplate.from_template(reduce_template)\n",
        "# 요약한것들을 doc_summaries에 넣는다. 100단어여야하고 한글로 답변을 달라\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "03ZSe_WYp1to"
      },
      "source": [
        "Map-Reduce chains"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GPt37xR_p0oN"
      },
      "outputs": [],
      "source": [
        "# 1. Reduce chain\n",
        "reduce_chain = LLMChain(llm=llm, prompt=reduce_prompt)\n",
        "\n",
        "# StuffDocumentChain : 한꺼번에 요약 가능한 chain\n",
        "# doc_summaries 부분에 여섯개의 document 요약한것을 대치\n",
        "# Takes a list of documents, combines them into a single string, and passes this to an LLMChain\n",
        "combine_documents_chain = StuffDocumentsChain(\n",
        "    llm_chain=reduce_chain, document_variable_name=\"doc_summaries\"\n",
        ")\n",
        "\n",
        "# reduce Chain 완료\n",
        "# Combines and iteravely reduces the mapped documents\n",
        "reduce_documents_chain = ReduceDocumentsChain(\n",
        "    # This is final chain that is called.\n",
        "    combine_documents_chain=combine_documents_chain,\n",
        "    # If documents exceed context for `StuffDocumentsChain`\n",
        "    collapse_documents_chain=combine_documents_chain,\n",
        "    # The maximum number of tokens to group documents into.\n",
        "    token_max=4000,\n",
        ")\n",
        "\n",
        "\n",
        "# 2. Map chain\n",
        "map_chain = LLMChain(llm=llm, prompt=map_prompt)\n",
        "\n",
        "# Combining documents by mapping a chain over them, then combining results\n",
        "map_reduce_chain = MapReduceDocumentsChain(\n",
        "    # Map chain\n",
        "    llm_chain=map_chain,\n",
        "    # Reduce chain\n",
        "    reduce_documents_chain=reduce_documents_chain,\n",
        "    # The variable name in the llm_chain to put the documents in\n",
        "    document_variable_name=\"docs\",\n",
        "    # Return the results of the map steps in the output\n",
        "    return_intermediate_steps=False,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HhP0AdLkqs6N"
      },
      "source": [
        "Run"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o4oh3-Kdqtyd",
        "outputId": "c914095a-30de-49f5-e9bf-c73f312a3a66"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `run` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
            "  warn_deprecated(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "주요 주제는 과거와 현재의 관계, 인간관계와 외로움, 그리고 사회적 상호작용과 인간적 연결이다. 이 소설은 시간에 대한 관점, 철학적 시각, 여성주의적 시각, 그리고 개인적 성장을 다루며, 자기인식과 자기개선, 관계와 외로움, 사회적 상호작용과 인간적 연결에 대한 중요성을 강조한다.\n"
          ]
        }
      ],
      "source": [
        "sum_result = map_reduce_chain.run(split_docs)\n",
        "\n",
        "print(sum_result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YL2vWiUrqx_x"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F4h5A22kzy4V"
      },
      "source": [
        "UI using Gradio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5stMDFMkzzMO",
        "outputId": "fbb73d49-4b9f-42f1-af53-b2bff160065e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.1/17.1 MB\u001b[0m \u001b[31m34.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.9/91.9 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m313.6/313.6 kB\u001b[0m \u001b[31m29.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.9/8.9 MB\u001b[0m \u001b[31m46.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.9/71.9 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for ffmpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install -q gradio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 649
        },
        "id": "33d3eWhPz1D-",
        "outputId": "f7a74058-674f-484f-96e6-48931978bdfe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "Running on public URL: https://139c13123a3a6fd217.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"https://139c13123a3a6fd217.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:115: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
          ]
        }
      ],
      "source": [
        "import gradio as gr\n",
        "import re\n",
        "\n",
        "def extract_video_id(url):\n",
        "    youtube_regex = (r'(https?://)?(www\\.)?'\n",
        "        '(youtube|youtu|youtube-nocookie)\\.(com|be)/'\n",
        "        '(watch\\?v=|embed/|v/|.+\\?v=)?([^&=%\\?]{11})')\n",
        "    youtube_pattern = re.compile(youtube_regex)\n",
        "    match = youtube_pattern.match(url)\n",
        "    if not match:\n",
        "        return None\n",
        "    return match.group(6)\n",
        "\n",
        "def summarize(url):\n",
        "    yt = YouTube(url)\n",
        "\n",
        "    yt.streams.filter(only_audio=True).first().download(\n",
        "        output_path='.', filename='input.mp3')\n",
        "\n",
        "    result = model.transcribe(\"input.mp3\")\n",
        "\n",
        "    docs = [Document(page_content=x) for x in text_splitter.split_text(result[\"text\"])]\n",
        "    split_docs = text_splitter.split_documents(docs)\n",
        "\n",
        "    sum_result = map_reduce_chain.run(split_docs)\n",
        "\n",
        "    video_id = extract_video_id(url)\n",
        "    embed = f\"\"\"<iframe width='560' height='315' src='https://www.youtube.com/embed/{video_id}' frameborder='0' allowfullscreen></iframe>\"\"\"\n",
        "\n",
        "    return sum_result, embed\n",
        "\n",
        "demo = gr.Interface(\n",
        "    fn=summarize,\n",
        "    inputs=gr.Textbox(label=\"URL\"),\n",
        "    outputs=[gr.TextArea(label=\"Summary\"), gr.HTML()],\n",
        "    # outputs=gr.TextArea(label=\"Summary\"),\n",
        ")\n",
        "\n",
        "demo.launch(debug=True, share=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6pLGd2o8z61Q"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
